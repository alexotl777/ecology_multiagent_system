"""–ê–≥–µ–Ω—Ç –∞–Ω–∞–ª–∏–∑–∞ —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
import logging
from typing import Dict
from datetime import datetime, timedelta
from langchain_core.messages import AIMessage
from langchain_groq import ChatGroq

from config import settings
from data_tools import get_recent_measurements, analyze_trend, detect_anomalies
from db.database import get_session
from db.models import Analysis

logger = logging.getLogger(__name__)


class AnalyzerAgent:
    """–ê–≥–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤ –∏ –∞–Ω–æ–º–∞–ª–∏–π"""
    
    def __init__(self):
        self.name = "AnalyzerAgent"
        self.llm = ChatGroq(
            temperature=0.3,
            model_name=settings.GROQ_MODEL,
            groq_api_key=settings.GROQ_API_KEY
        )
    
    async def execute(self, state: Dict) -> Dict:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö"""
        logger.info(f"{self.name}: Starting analysis")
        
        analysis_results = []
        period_end = datetime.utcnow()
        period_start = period_end - timedelta(hours=168)
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é
        async for session in get_session():
            measurements = await get_recent_measurements(session, hours=168)
        
        if not measurements:
            message = AIMessage(content="‚ö†Ô∏è No data available for analysis")
            return {"messages": state["messages"] + [message], "data": {}}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ª–æ–∫–∞—Ü–∏—è–º
        locations_data = {}
        for m in measurements:
            if m.location_name not in locations_data:
                locations_data[m.location_name] = {"pm25": [], "pm10": [], "no2": [], "temp": []}
            
            if m.pm25:
                locations_data[m.location_name]["pm25"].append(m.pm25)
            if m.pm10:
                locations_data[m.location_name]["pm10"].append(m.pm10)
            if m.no2:
                locations_data[m.location_name]["no2"].append(m.no2)
            if m.temperature:
                locations_data[m.location_name]["temp"].append(m.temperature)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–¥—ã –∏ –∞–Ω–æ–º–∞–ª–∏–∏
        for location, data in locations_data.items():
            pm25_trend = analyze_trend(data["pm25"]) if data["pm25"] else "no_data"
            pm25_anomalies = detect_anomalies(data["pm25"]) if len(data["pm25"]) > 3 else []
            avg_pm25 = sum(data["pm25"]) / len(data["pm25"]) if data["pm25"] else 0
            max_pm25 = max(data["pm25"]) if data["pm25"] else 0
            min_pm25 = min(data["pm25"]) if data["pm25"] else 0
            avg_temp = sum(data["temp"]) / len(data["temp"]) if data["temp"] else 0
            
            analysis_results.append({
                "location": location,
                "pm25_trend": pm25_trend,
                "pm25_anomalies_count": len(pm25_anomalies),
                "avg_pm25": avg_pm25,
                "max_pm25": max_pm25,
                "min_pm25": min_pm25,
                "avg_temp": avg_temp,
            })
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –¥–ª—è –∫–∞–∂–¥–æ–π –ª–æ–∫–∞—Ü–∏–∏
        analysis_text = "\n".join([
            f"üìç {r['location']}:\n"
            f"   - –¢—Ä–µ–Ω–¥: {r['pm25_trend']}\n"
            f"   - PM2.5: —Å—Ä–µ–¥–Ω–µ–µ={r['avg_pm25']:.1f}, –º–∏–Ω={r['min_pm25']:.1f}, –º–∞–∫—Å={r['max_pm25']:.1f}\n"
            f"   - –ê–Ω–æ–º–∞–ª–∏–π: {r['pm25_anomalies_count']}\n"
            f"   - –°—Ä–µ–¥–Ω—è—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {r['avg_temp']:.1f}¬∞C"
            for r in analysis_results[:10]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10 –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        ])
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM
        detailed_prompt = f"""–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç-—ç–∫–æ–ª–æ–≥, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –∫–∞—á–µ—Å—Ç–≤–æ –≤–æ–∑–¥—É—Ö–∞ –≤ –∫—Ä—É–ø–Ω—ã—Ö –≥–æ—Ä–æ–¥–∞—Ö –†–æ—Å—Å–∏–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –Ω–µ–¥–µ–ª—é.

–î–ê–ù–ù–´–ï –ó–ê –ù–ï–î–ï–õ–Æ:
{analysis_text}

–°–ü–†–ê–í–ö–ê:
- PM2.5 –Ω–æ—Ä–º–∞: –¥–æ 25 Œºg/m¬≥ (–í–û–ó), 35 Œºg/m¬≥ (–¥–æ–ø—É—Å—Ç–∏–º–æ)
- AQI: 0-50 —Ö–æ—Ä–æ—à–æ, 51-100 —É–º–µ—Ä–µ–Ω–Ω–æ, 101+ –≤—Ä–µ–¥–Ω–æ

–°–æ—Å—Ç–∞–≤—å –ü–û–î–†–û–ë–ù–´–ô –∞–Ω–∞–ª–∏–∑ (4-6 –∞–±–∑–∞—Ü–µ–≤) –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ:

1. **–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏**: –∫–∞–∫–∏–µ –≥–æ—Ä–æ–¥–∞ –≤ –ª—É—á—à–µ–º/—Ö—É–¥—à–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –µ—Å—Ç—å –ª–∏ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è?

2. **–¢—Ä–µ–Ω–¥—ã –∏ –¥–∏–Ω–∞–º–∏–∫–∞**: –∫–∞–∫–∏–µ –≥–æ—Ä–æ–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É—Ö—É–¥—à–µ–Ω–∏–µ (increasing), —É–ª—É—á—à–µ–Ω–∏–µ (decreasing) –∏–ª–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å?

3. **–ê–Ω–æ–º–∞–ª–∏–∏ –∏ –≤—ã–±—Ä–æ—Å—ã**: –≥–¥–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã —Ä–µ–∑–∫–∏–µ —Å–∫–∞—á–∫–∏ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è, –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã (–ø–æ–≥–æ–¥–∞, —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å)?

4. **–†–∏—Å–∫–∏ –¥–ª—è –∑–¥–æ—Ä–æ–≤—å—è**: –¥–ª—è –∫–∞–∫–∏—Ö –≥—Ä—É–ø–ø –Ω–∞—Å–µ–ª–µ–Ω–∏—è —Ç–µ–∫—É—â–∞—è –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–ø–∞—Å–Ω–∞, –∫–∞–∫–∏–µ —Å–∏–º–ø—Ç–æ–º—ã –≤–æ–∑–º–æ–∂–Ω—ã?

5. **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**: —á—Ç–æ —Å–æ–≤–µ—Ç—É–µ—à—å –∂–∏—Ç–µ–ª—è–º (–æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –ø—Ä–æ–≥—É–ª–∫–∏, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–∞—Å–∫–∏, –ø—Ä–æ–≤–µ—Ç—Ä–∏–≤–∞–Ω–∏–µ) –∏ –≤–ª–∞—Å—Ç—è–º (–∫–æ–Ω—Ç—Ä–æ–ª—å –≤—ã–±—Ä–æ—Å–æ–≤, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç)?

–ü–∏—à–∏ –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, –Ω–æ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ. –ò—Å–ø–æ–ª—å–∑—É–π emoji –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏."""

        try:
            # –ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ
            summary_prompt = f"–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö: {analysis_text}\n\n–ù–∞–ø–∏—à–∏ –ö–†–ê–¢–ö–û–ï —Ä–µ–∑—é–º–µ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è) –æ–±—â–µ–π —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –æ–±—Å—Ç–∞–Ω–æ–≤–∫–∏."
            summary_response = await self.llm.ainvoke(summary_prompt)
            summary = summary_response.content
            
            # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            detailed_response = await self.llm.ainvoke(detailed_prompt)
            detailed_analysis = detailed_response.content
            
        except Exception as e:
            logger.error(f"LLM analysis error: {e}")
            summary = "–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω, –¥–∞–Ω–Ω—ã–µ —Å–æ–±—Ä–∞–Ω—ã –∑–∞ –Ω–µ–¥–µ–ª—é."
            detailed_analysis = "–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –ë–î
        async for session in get_session():
            for result in analysis_results:
                try:
                    analysis = Analysis(
                        analysis_type="weekly_trend",
                        location_name=result["location"],
                        pm25_trend=result["pm25_trend"],
                        pm25_avg=result["avg_pm25"],
                        anomalies_count=result["pm25_anomalies_count"],
                        summary=summary,
                        detailed_analysis=detailed_analysis,
                        period_start=period_start,
                        period_end=period_end
                    )
                    session.add(analysis)
                except Exception as e:
                    logger.error(f"Error saving analysis: {e}")
            
            await session.commit()
        
        message = AIMessage(content=f"üìä –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω:\n\n{summary}\n\n–ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ –≤–∫–ª–∞–¥–∫–µ '–ê–Ω–∞–ª–∏–∑'")
        
        return {
            "messages": state["messages"] + [message],
            "data": {"analysis": analysis_results, "summary": summary, "detailed_analysis": detailed_analysis}
        }
